{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2470778 entries, 0 to 2470777\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Unnamed: 0    object \n",
      " 1   subreddit     object \n",
      " 2   title         object \n",
      " 3   body          object \n",
      " 4   upvotes       float64\n",
      " 5   created_utc   float64\n",
      " 6   num_comments  float64\n",
      " 7   label         float64\n",
      "dtypes: float64(4), object(4)\n",
      "memory usage: 150.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/pl2b7v5d24zg2_4z7z3r8jfw0000gn/T/ipykernel_43023/3595657788.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./Datasets/reddit_depression_dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./Datasets/reddit_depression_dataset.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/pl2b7v5d24zg2_4z7z3r8jfw0000gn/T/ipykernel_43023/2694964529.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['label'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in 'label' column\n",
    "print(df['label'].isna().sum())\n",
    "\n",
    "# Option 1: Fill NaNs with a specific value (e.g., 0)\n",
    "df['label'].fillna(0, inplace=True)\n",
    "\n",
    "# Option 2: Drop rows with NaN values in 'label'\n",
    "df.dropna(subset=['label'], inplace=True)\n",
    "\n",
    "# Convert 'label' to int after handling missing values\n",
    "df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/pl2b7v5d24zg2_4z7z3r8jfw0000gn/T/ipykernel_43023/2086827702.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['text'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['title'] + ' ' + df['body']\n",
    "\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "# Combine 'title' and 'body' into one column and handle NaN values\n",
    "df['text'] = df['title'].fillna('') + ' ' + df['body'].fillna('')\n",
    "\n",
    "# Check for any remaining NaN in the 'text' column (just in case)\n",
    "df['text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/pl2b7v5d24zg2_4z7z3r8jfw0000gn/T/ipykernel_43023/525539520.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['label'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'label' has no missing values and is of integer type\n",
    "df['label'].fillna(0, inplace=True)\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Combine 'title' and 'body' into 'text'\n",
    "df['text'] = df['title'].fillna('') + ' ' + df['body'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47951</td>\n",
       "      <td>DeepThoughts</td>\n",
       "      <td>Deep thoughts underdog</td>\n",
       "      <td>Only when we start considering ourselves, the ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.405309e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Deep thoughts underdog Only when we start cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47952</td>\n",
       "      <td>DeepThoughts</td>\n",
       "      <td>I like this sub, there's only two posts yet I ...</td>\n",
       "      <td>Anyway: Human Morality is a joke so long as th...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.410568e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>I like this sub, there's only two posts yet I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47957</td>\n",
       "      <td>DeepThoughts</td>\n",
       "      <td>Rebirth!</td>\n",
       "      <td>Hello. \\nI am the new guy in charge here (Besi...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.416458e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rebirth! Hello. \\nI am the new guy in charge h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47959</td>\n",
       "      <td>DeepThoughts</td>\n",
       "      <td>\"I want to be like water. I want to slip throu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.416512e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I want to be like water. I want to slip throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47960</td>\n",
       "      <td>DeepThoughts</td>\n",
       "      <td>Who am I?</td>\n",
       "      <td>You could take any one cell in my body and kil...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.416516e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Who am I? You could take any one cell in my bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0     subreddit                                              title  \\\n",
       "0      47951  DeepThoughts                             Deep thoughts underdog   \n",
       "1      47952  DeepThoughts  I like this sub, there's only two posts yet I ...   \n",
       "2      47957  DeepThoughts                                           Rebirth!   \n",
       "3      47959  DeepThoughts  \"I want to be like water. I want to slip throu...   \n",
       "4      47960  DeepThoughts                                          Who am I?   \n",
       "\n",
       "                                                body  upvotes   created_utc  \\\n",
       "0  Only when we start considering ourselves, the ...      4.0  1.405309e+09   \n",
       "1  Anyway: Human Morality is a joke so long as th...      4.0  1.410568e+09   \n",
       "2  Hello. \\nI am the new guy in charge here (Besi...      6.0  1.416458e+09   \n",
       "3                                                NaN     25.0  1.416512e+09   \n",
       "4  You could take any one cell in my body and kil...      5.0  1.416516e+09   \n",
       "\n",
       "   num_comments  label                                               text  \n",
       "0           NaN      0  Deep thoughts underdog Only when we start cons...  \n",
       "1           1.0      0  I like this sub, there's only two posts yet I ...  \n",
       "2           1.0      0  Rebirth! Hello. \\nI am the new guy in charge h...  \n",
       "3           2.0      0  \"I want to be like water. I want to slip throu...  \n",
       "4           4.0      0  Who am I? You could take any one cell in my bo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.85833\teval-auc:0.85861\n",
      "[10]\ttrain-auc:0.91009\teval-auc:0.90976\n",
      "[20]\ttrain-auc:0.92185\teval-auc:0.92138\n",
      "[30]\ttrain-auc:0.93013\teval-auc:0.92942\n",
      "[40]\ttrain-auc:0.93603\teval-auc:0.93523\n",
      "[50]\ttrain-auc:0.94079\teval-auc:0.94002\n",
      "[60]\ttrain-auc:0.94408\teval-auc:0.94327\n",
      "[70]\ttrain-auc:0.94689\teval-auc:0.94595\n",
      "[80]\ttrain-auc:0.94899\teval-auc:0.94808\n",
      "[90]\ttrain-auc:0.95103\teval-auc:0.95002\n",
      "[100]\ttrain-auc:0.95267\teval-auc:0.95164\n",
      "[110]\ttrain-auc:0.95409\teval-auc:0.95300\n",
      "[120]\ttrain-auc:0.95535\teval-auc:0.95420\n",
      "[130]\ttrain-auc:0.95646\teval-auc:0.95528\n",
      "[140]\ttrain-auc:0.95749\teval-auc:0.95626\n",
      "[150]\ttrain-auc:0.95848\teval-auc:0.95717\n",
      "[160]\ttrain-auc:0.95930\teval-auc:0.95795\n",
      "[170]\ttrain-auc:0.96003\teval-auc:0.95862\n",
      "[180]\ttrain-auc:0.96075\teval-auc:0.95928\n",
      "[190]\ttrain-auc:0.96147\teval-auc:0.95993\n",
      "[200]\ttrain-auc:0.96209\teval-auc:0.96051\n",
      "[210]\ttrain-auc:0.96269\teval-auc:0.96110\n",
      "[220]\ttrain-auc:0.96322\teval-auc:0.96161\n",
      "[230]\ttrain-auc:0.96372\teval-auc:0.96204\n",
      "[240]\ttrain-auc:0.96425\teval-auc:0.96252\n",
      "[250]\ttrain-auc:0.96470\teval-auc:0.96292\n",
      "[260]\ttrain-auc:0.96510\teval-auc:0.96328\n",
      "[270]\ttrain-auc:0.96553\teval-auc:0.96364\n",
      "[280]\ttrain-auc:0.96594\teval-auc:0.96403\n",
      "[290]\ttrain-auc:0.96631\teval-auc:0.96437\n",
      "[300]\ttrain-auc:0.96668\teval-auc:0.96469\n",
      "[310]\ttrain-auc:0.96700\teval-auc:0.96497\n",
      "[320]\ttrain-auc:0.96735\teval-auc:0.96530\n",
      "[330]\ttrain-auc:0.96766\teval-auc:0.96558\n",
      "[340]\ttrain-auc:0.96797\teval-auc:0.96586\n",
      "[350]\ttrain-auc:0.96829\teval-auc:0.96612\n",
      "[360]\ttrain-auc:0.96856\teval-auc:0.96635\n",
      "[370]\ttrain-auc:0.96884\teval-auc:0.96660\n",
      "[380]\ttrain-auc:0.96909\teval-auc:0.96681\n",
      "[390]\ttrain-auc:0.96937\teval-auc:0.96705\n",
      "[400]\ttrain-auc:0.96962\teval-auc:0.96725\n",
      "[410]\ttrain-auc:0.96984\teval-auc:0.96743\n",
      "[420]\ttrain-auc:0.97007\teval-auc:0.96763\n",
      "[430]\ttrain-auc:0.97030\teval-auc:0.96783\n",
      "[440]\ttrain-auc:0.97054\teval-auc:0.96802\n",
      "[450]\ttrain-auc:0.97075\teval-auc:0.96820\n",
      "[460]\ttrain-auc:0.97095\teval-auc:0.96837\n",
      "[470]\ttrain-auc:0.97117\teval-auc:0.96854\n",
      "[480]\ttrain-auc:0.97139\teval-auc:0.96873\n",
      "[490]\ttrain-auc:0.97158\teval-auc:0.96887\n",
      "[500]\ttrain-auc:0.97176\teval-auc:0.96903\n",
      "[510]\ttrain-auc:0.97193\teval-auc:0.96917\n",
      "[520]\ttrain-auc:0.97213\teval-auc:0.96933\n",
      "[530]\ttrain-auc:0.97229\teval-auc:0.96947\n",
      "[540]\ttrain-auc:0.97244\teval-auc:0.96960\n",
      "[550]\ttrain-auc:0.97260\teval-auc:0.96974\n",
      "[560]\ttrain-auc:0.97277\teval-auc:0.96987\n",
      "[570]\ttrain-auc:0.97293\teval-auc:0.97000\n",
      "[580]\ttrain-auc:0.97308\teval-auc:0.97011\n",
      "[590]\ttrain-auc:0.97324\teval-auc:0.97024\n",
      "[600]\ttrain-auc:0.97339\teval-auc:0.97035\n",
      "[610]\ttrain-auc:0.97354\teval-auc:0.97047\n",
      "[620]\ttrain-auc:0.97368\teval-auc:0.97059\n",
      "[630]\ttrain-auc:0.97382\teval-auc:0.97069\n",
      "[640]\ttrain-auc:0.97398\teval-auc:0.97082\n",
      "[650]\ttrain-auc:0.97413\teval-auc:0.97093\n",
      "[660]\ttrain-auc:0.97425\teval-auc:0.97103\n",
      "[670]\ttrain-auc:0.97438\teval-auc:0.97113\n",
      "[680]\ttrain-auc:0.97452\teval-auc:0.97124\n",
      "[690]\ttrain-auc:0.97463\teval-auc:0.97132\n",
      "[700]\ttrain-auc:0.97476\teval-auc:0.97142\n",
      "[710]\ttrain-auc:0.97487\teval-auc:0.97151\n",
      "[720]\ttrain-auc:0.97499\teval-auc:0.97159\n",
      "[730]\ttrain-auc:0.97511\teval-auc:0.97167\n",
      "[740]\ttrain-auc:0.97520\teval-auc:0.97174\n",
      "[750]\ttrain-auc:0.97534\teval-auc:0.97185\n",
      "[760]\ttrain-auc:0.97545\teval-auc:0.97194\n",
      "[770]\ttrain-auc:0.97556\teval-auc:0.97203\n",
      "[780]\ttrain-auc:0.97565\teval-auc:0.97209\n",
      "[790]\ttrain-auc:0.97578\teval-auc:0.97219\n",
      "[800]\ttrain-auc:0.97589\teval-auc:0.97226\n",
      "[810]\ttrain-auc:0.97600\teval-auc:0.97235\n",
      "[820]\ttrain-auc:0.97610\teval-auc:0.97242\n",
      "[830]\ttrain-auc:0.97620\teval-auc:0.97250\n",
      "[840]\ttrain-auc:0.97630\teval-auc:0.97257\n",
      "[850]\ttrain-auc:0.97640\teval-auc:0.97265\n",
      "[860]\ttrain-auc:0.97649\teval-auc:0.97272\n",
      "[870]\ttrain-auc:0.97659\teval-auc:0.97279\n",
      "[880]\ttrain-auc:0.97668\teval-auc:0.97286\n",
      "[890]\ttrain-auc:0.97677\teval-auc:0.97293\n",
      "[900]\ttrain-auc:0.97686\teval-auc:0.97299\n",
      "[910]\ttrain-auc:0.97694\teval-auc:0.97306\n",
      "[920]\ttrain-auc:0.97703\teval-auc:0.97312\n",
      "[930]\ttrain-auc:0.97711\teval-auc:0.97318\n",
      "[940]\ttrain-auc:0.97719\teval-auc:0.97324\n",
      "[950]\ttrain-auc:0.97727\teval-auc:0.97330\n",
      "[960]\ttrain-auc:0.97735\teval-auc:0.97335\n",
      "[970]\ttrain-auc:0.97743\teval-auc:0.97341\n",
      "[980]\ttrain-auc:0.97750\teval-auc:0.97346\n",
      "[990]\ttrain-auc:0.97758\teval-auc:0.97352\n",
      "[999]\ttrain-auc:0.97764\teval-auc:0.97356\n"
     ]
    }
   ],
   "source": [
    "evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = bst.predict(dtest)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96    398074\n",
      "           1       0.88      0.79      0.84     96082\n",
      "\n",
      "    accuracy                           0.94    494156\n",
      "   macro avg       0.92      0.88      0.90    494156\n",
      "weighted avg       0.94      0.94      0.94    494156\n",
      "\n",
      "Confusion Matrix:\n",
      " [[388044  10030]\n",
      " [ 19779  76303]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model(\"xgboost_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming your original text data is in df['text']\u001b[39;00m\n\u001b[1;32m      5\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert the sparse matrix to a dense array\u001b[39;00m\n\u001b[1;32m      9\u001b[0m X_dense \u001b[38;5;241m=\u001b[39m X_transformed\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your original text data is in df['text']\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_transformed = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Convert the sparse matrix to a dense array\n",
    "X_dense = X_transformed.toarray()\n",
    "\n",
    "# Create a DataFrame with the processed features\n",
    "processed_df = pd.DataFrame(X_dense)\n",
    "\n",
    "# Optionally, add the target column (if needed)\n",
    "processed_df['label'] = df['label'].values\n",
    "\n",
    "# Save to CSV\n",
    "processed_df.to_csv('preprocessed_reddit_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
